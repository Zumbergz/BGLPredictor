## Intro

Type 1 diabetes mellitus (T1DM) is an autoimmune disease that typically manifests itself in those between 10 and 14 years of age. That is not to say, however, that diagnosis of T1DM is restricted to those individuals within this age range, and whilst it is rare for diagnosis to be made in individuals over 40, it is possible for T1DM to occur at any age. T1DM is characterised by the destruction of the beta-cells within the pancreas which are responsible for producing insulin. This loss of insulin producing beta cells means that there is an inability for T1DM patients to regulate their own blood glucose levels, and leads to hyperglycemia (blood glucose levels being too high). As such, T1DM patients are reliant on external insulin to control the glycemic levels in their body. Diagnosis of the condition is based on hyperglycemia, with a fasting blood glucose concentration above 7.0 mmol/L being characterised as enough to diagnose. Other symptoms commonly seen before diagnosis are polyuria, polydipsia and weight loss.

According to the WHO, blood glucose levels should be between 3.9 mmol/L and 5.6mmol/L for ordinary people and between 5 mmol/L and 9 mmol/L for diabetic patients. As a result of this, there is a constant need for diabetics to manage their blood glucose levels, with the aim of spending as much time within this range as possible, and avoiding hyperglycemia and hypoglycemia (blood glucose levels too low). Both hyperglycemia and hypoglycemia are serious conditions and can lead to life threatening situations for patients; making precision when managing blood glucose levels a matter of life and death. Patients who spend extended periods of time in a hyperglycemic state can suffer from kidney damage, nerve damage, damage to the blood vessels of the retina, and complications with bones and joints. In extreme cases of hyperglycemia, diabetic ketoacidosis can occur, which, if left untreated, can lead to a life-threatening diabetic coma. Meanwhile, hypoglycemia affords a range of different issues, ranging from slurred speech and numbness to seizures, coma and death in extreme cases. 

With an estimated 422 million people worldwide suffering from diabetes, making it the 3rd most common chronic illness in the world, it is clear that there is a need and a great benefit to be gained from using technology to help patients more accurately manage their blood glucose levels. Unfortunately, regulating blood glucose levels is not an exact science, and there are around 48 different factors that can impact a patient's blood glucose levels. The predominant factor is carbohydrates ingested by the patient. Carbohydrates are broken down by the amylase enzyme into glucose which is transferred into the blood stream to be absorbed by cells; clearly having a direct impact on the levels of glucose in the blood. Other major factors include any physical activity done by the patient, and any external insulin taken by the patient. Whilst these factors are more easily measurable for patients, and thus can be adapted to and controlled, other factors such as stress, illness and injury, and hormonal changes can also have a substantial impact on blood glucose levels, whilst being much more difficult to manage. This makes the task of predicting how blood glucose levels will change and responding accordingly difficult for T1DM patients and machines alike - one small change can lead to large variations in behaviour.  

The end vision of diabetes related technology is known as the Artificial Pancreas (AP) and consists of a fully closed-loop system where a T1DM patient would have to do no management of their blood glucose level at all; the AP would handle everything. Unfortunately, due to the problems in variation and some other issues we will cover below, the creation of this AP system still seems to be far in the future. However, that is not to say that technology has had no impact on the lives of T1DM patients, as there have been many advances which have made noticeable impacts on improving the quality of life of patients. Introduced in 1981, insulin pens are devices that allow patients to inject insulin directly into their body. Coupled together with small, easy to use glucometers which were introduced in the 1980s, patients were able to frequently monitor their blood glucose levels, and respond accordingly by either using their insulin pens, or ingesting more glucose. This method of self-monitoring of Blood Glucose (SMBG) has significant drawbacks as blood is sampled intermittently, providing only short insights of glucose concentrations, whilst ignoring ongoing glucose fluctuations. With the idea of being able to monitor blood glucose at all times, Continuous Glucose Monitoring (CGM) devices were introduced that measures glucose concentrations at intervals (usually between 1-5 min), and then transmits/stores those values. Alongside the invention of the insulin pump, a device that allows programmable infusions of insulin over long, or short, periods of time, diabetic patients were given a much more reliable way of constantly monitoring, and regulating their blood glucose levels.

The creation of CGM devices also lead to a new capability - the ability to create blood glucose datasets by accesing the data stored in the CGM; datasets which are needed to train accurate Machine Learning (ML) models. It is clear that the capability to accurately predict when one might suffer a hyperglycemic, or hypoglycemic, episode would be invaluable to a T1DM patient, as it would allow them to behave proactively to prevent the episode from ever occurring, rather than the current reactionary method, which requires a hypo/hyperglycemic episode to be taking place before we can detect its presence. We name the amount of time into the future which we forecast the Prediction Horizon (PH). Current prediction horizons available to T1DM patients are very short (~5 mins? Find a stat), and thus don't give ample time for patients to react to predicted issues. As such, much work has been done in applying ML techniques to improve the length of the PH to a length of hours instead of minutes, but as of yet no concrete solution to the problem has been found. This is due to a variety of reasons, such as the variability of a patient's BG level due to uncontrollable factors day by day which was mentioned earlier, as well as some other issues that we will discuss later as we take a look at and disccuss different approaches that have been experimented with to solve this very problem.

## Main Bit
#### Intro
Machine learning is a field of Artificial Intelligence that focuses on learning through observing patterns in large quantities of past data, and iteratively improving accuracy at a given task. In the context of T1DM, the large quantities of past data refer to the patient's blood glucose levels over a period of months (as well as other points of interest such as exercise done / carbohydrate intake), whilst the task to improve at is predicting the BG levels of the patient for a specified PH. In particular we will look at Neural Networks (NN), a kind of Machine learning model that is able to learn very complex relationships between data by minimising the value of an error function, through iterative processes such as gradient descent. This error function can be specified to suit the model as needed and it is common, in the case of blood glucose forecasting, to see an error function comparing the absolute difference between forecasted blood glucose levels, and real recorded blood glucose levels. Much work has been done researching the applications of different kinds of NN to blood glucose forecasting, as it was believed that NNs would be able to solve the problem of intersubject variability - by training a new network on each individual's data. 

When training neural networks, there is much debate amongst researchers about what to include and what not to include within the input parameters to the network. Some believe that just the CGM data is sufficient, claiming that the inclusiuon of other measures, such as carbohydrate intake, would simply increase variance and decrease model performance. This is sharply contrasted by researchers who have experimented with both complex and simple physiological models to try and model the effect that factors such as exercise and insulin intake will have on future glucose levels. There is much debate about the correlation between past glucose levels and future levels, with some using only the current blood glucose levels as an input to the model, and others using many past readings to inform future predictions. Whilst there is much diversity amongst the methods employed, unfortunately, the overarching theme from most NN approaches is that they are very accurate at shorter PH (~30 minutes), but that accuracy quickly drops off at larger PH (~6 hours). 

### ANN
One such example of the application of NNs to the task of blood glucose prediction was by ((**Paper 3, insert ref**)), who attempted to use a NN trained on only CGM data. The model considered the preceding 20 minutes of CGM data, and attempted to predict BG levels at 3 different PHs of 15, 30 and 45 minutes. They would measure the accuracy of the model using the Root Mean Squared Error (RMSE) - a widely used metric for BG prediction models that takes the square root of the sum of the squares of all prediction errors - and the Prediction Delay (PD) - a metric that takes into account the delay between when certain features of the CGM data were seen in the original data and the predicted data (for instance the time gap between a peak appearing in the original and predicted data). When making a prediction, they compared two different approaches - their standard NN model that would make one prediction across the PH, and an AutoRegressive Model (ARM). In an ARM, the model makes the prediction one step at a time, and uses a recursive algorithm to allow each prediction to inform subsequent predictions, trying to capture the relationships between previous and future BG levels more accurately. They found that across the 15, 30 and 45 minute PHs there was a RMSE of ~10, 18, 27, mg/dL respectively. For upward trends in the data, there was a PD of 4, 9 and 14 minutes respectively, and for downward trends, a PD of 5, 15 and 26 minutes was seen. 

This use of a basic NN highlights some of the main problems with this approach when applied to blood glucose prediction - firstly that the accuracy falls of very quickly, with 2.7 times worse performance over a short difference in time of 30 minutes, and secondly that the model is much quicker at recognising upward than downward trends. This is a major issue, as downward trends lead to hypoglycemic episodes, which can be far more dangerous in the short term. To try and combat the first of these problems, ((**Paper 5 insert ref**)) included time-domain attributes along with their 

#### RNN


#### CNN


